---
title: "Test missMDA"
output:
  rmarkdown::html_vignette
  html_document:
    toc: true
    toc_float: true
    df_print: paged
    number_sections: true
---
```{r setup, echo=FALSE, cache=FALSE}

knitr::opts_chunk$set(error = TRUE, cache = TRUE)
```

Les dépendances (voir fichier `missMDA_function` pour les fonctions modifiées) :

```{r dependencies, message=FALSE, warning=FALSE}

library(MASS)
library(norm)
library(VIM)
library(ggplot2)
library(ggpubr)
library(naniar)
library(usethis)
library(rlist)
library(devtools)
library(abind)
library(missMethods)
library(gbutils)
library(gdata)
library(stats)
library(missMDA)
library(FactoMineR)

source_url("https://raw.githubusercontent.com/R-miss-tastic/website/master/static/how-to/generate/amputation.R")

source("missMDA_function.R")
```

# Generate data

## Complete data

We generate a complete data set (Y1, Y2, Y3, Y4, Y5, Y6, Y7, Y8) with (Y1, Y2, Y3) ~ N(u1, S1), (Y4, Y5)~N(u2,S2), Y6~P($\lambda$) and Y7,Y8~Binomial(prob).

```{r generate_complete}

n <- 10000
mu.X <- c(1, 2, 3)
Sigma.X <- matrix(c(
  9, 3, 2,
  3, 4, 0,
  2, 0, 1
), nrow = 3)
X.complete.cont <- mvrnorm(n, mu.X, Sigma.X) # multivariate normal distribution

mu1.X <- c(9, 8)
Sigma1.X <- matrix(c(
  16, 14,
  14, 25
), nrow = 2)

X.complete.cont1 <- mvrnorm(n, mu1.X, Sigma1.X) # multivariate normal distribution

lambda <- 4.3
X.complete.discr <- rpois(n, lambda) # poisson distribution


X.complete.cat <- rbinom(n, size = 5, prob = 0.4) # binomial

X.complete.cat2 <- rbinom(n, size = 7, prob = 0.6) # binomial

X.complete <- data.frame(cbind(X.complete.cont, X.complete.cont1, X.complete.discr, X.complete.cat, X.complete.cat2))
X.complete[, 7] <- as.factor(X.complete[, 7])
levels(X.complete[, 7]) <- c("F", "E", "D", "C", "B", "A")
X.complete[, 8] <- as.factor(X.complete[, 8])
colnames(X.complete) <- c("Y1", "Y2", "Y3", "Y4", "Y5", "Y6", "Y7", "Y8")
head(X.complete)
```

## Add missingness

We produce some NA using the `produce_NA` routine advertised [here](https://rmisstastic.netlify.app/how-to/generate/misssimul) and linked from [rmisstastic](https://rmisstastic.netlify.app/data/). The function gets imported by the previous call to `source_url(...)`.

```{r add_missingness}

miss_perc <- 0.4
mar1 <- produce_NA(X.complete, mechanism = "MAR", perc.missing = miss_perc, by.patterns = F, logit.model = "MID")
X.mar1 <- mar1$data.incomp
R.mar1 <- data.frame(mar1$idx_newNA)
head(X.mar1)
```

# Imputation

## Original `estim_ncpFAMD` function (with memory error)

The following leads to a memory error :

```{r estim_ncpFAMD_memory_error}

ncp.pca <- estim_ncpFAMD(X.mar1, method.cv = "Kfold", verbose = T)$ncp
```

## `estim_ncpFAMD` function with some print functions (`estim_ncpFAMD_1` function in `missMDA_function.R`)

We add some prints to the function and we can see that the **numeric** colmuns (`Y1`,...,`Y6`) are passed to the `tab.disjonctif.NA` function.

```{r estim_ncpFAMD_error_print}

ncp.pca <- estim_ncpFAMD_1(X.mar1, method.cv = "Kfold", verbose = T)$ncp
```

The error comes from this calculation of MSE, where the whole dataset of `jeu` and `jeuNA` are passed to the `tab.disjonctif.NA` function:

```{r error_disj, eval=FALSE}
res[nbaxes - ncp.min + 1, sim] <- sum((tab.disj.comp - vrai.tab)^2, na.rm = TRUE) / (sum(is.na(tab.disjonctif.NA(jeuNA))) - sum(is.na(tab.disjonctif.NA(jeu))))
```

In order to avoid this memory error, we propose to use the combination of the quantitative columns and onehot form of the categorical columns. Here only the categorical variables are passed to the `tab.disjonctif.NA` function:

```{r correct_disj, eval=FALSE}
jeuNA.tab <- cbind(jeuNA[, 1:nbquanti, drop = F], tab.disjonctif.NA(jeuNA[, (nbquanti + 1):ncol(jeuNA), drop = F]))
res[nbaxes - ncp.min + 1, sim] <- sum((tab.disj.comp - vrai.tab)^2, na.rm = TRUE) / (sum(is.na(jeuNA.tab)) - sum(is.na(vrai.tab)))
# vrai.tab = cbind(jeu[,1:nbquanti,drop=F],tab.disjonctif.NA(jeu[,(nbquanti+1):ncol(jeu),drop=F])) is defined in the original code
```

## Changed `estim_ncpFAMD` function with `maxiter` (marked in `estim_ncpFAMD_2` function)

We could see from the result that the original error is not there anymore. However we get a convergence error. It may come from the same origin that is mentioned in this link: [https://groups.google.com/g/factominer-users/c/0foiGBch6Nw](factominer-users/c/0foiGBch6Nw).

```{r estim_ncpFAMD_error}

ncp.pca <- estim_ncpFAMD_2(X.mar1, method.cv = "Kfold", verbose = T, maxiter = 100)$ncp
```

## Changed `estim_ncpFAMD` function with `maxiter` (marked in `estim_ncpFAMD_2` function)

We tried to limit the `maxiter` parameter by passing it to the impute function. However, even the `maxiter` is set to 20, the convergence error still shows up.

So we dug deeper into the code. The error is generated in the `impute` function from `imputeMFA`, which itself is called by `imputeFAMD`. This error is only raised for categorical variables, and the corresponding code is shown here:

```{r error_estim, eval=FALSE}

if (any(MM[[g]] < 0)) {
  stop(paste("The algorithm fails to converge. Choose a number of components (ncp) less or equal than ", ncp - 1, " or a number of iterations (maxiter) less or equal than ", maxiter - 1, sep = ""))
}
```

Then we compared the implementation of this function with the algorithm mentioned in the original paper : *Handling missing values in multiple factor analysis*, François Husson, Julie Josse, 2013.

There are several differences on the preprocessing part between the algorithm described and the implementation. For example, in the centering preprocessing part, in the paper $Z = X * D^{-1/2} - M$ and in the implementation it seems that $Z = X * D^{-1/2} - \sqrt{M}$, where $Z$ is represented by `Zscale` or `aux.base` in the implementation.

We have also noticed that due to the computational error during the matrix calculation, the disjunctive table may change even for the observed part. So in the `impute_1` function, we added this line to decrease the inaccuracy.

```{r added_line, eval=FALSE}

####### correct some computational error e-17######
tab.disj[idx_obs[[g]], ] <- tab.disj.comp[[g]][idx_obs[[g]], ]
# idx_obs[[g]] is the set of index of the observed part
#################################################
```

However, these changes still could not explain the divergence error. So, we tried to print the disjunctive table and the MM matrix.

At last, it seems that if there is one category that has really small proportion of data, after `prodna` function, the proportion may be even smaller.The iterative PCA result tends to decrease the probability of this category until 0, and after some steps, this probability could be negative but very near 0, where the error is raised. During the PCA process, there is no constraint that the output of the disjunctive table should be positive, so the negative results could be generated during this process.

In order to deal with this special situation, we have several propositions:

* Add a threshold to the MM matrix (as shown in impute_1 function called by `estim_ncpFAMD_3`)
* When the probability of one category is less than a threshold (one value of MM < threshold), we redo the whole process without this category. For example, the categorical variable `Y8` ($Y_8 \in \{0,1,2,3,4,5,6,7\}$) has a very small probability to be 0. When `any(MM)<threshold`, we will consider that ($Y_8 \in \{1,2,3,4,5,6,7\}$) and recalculate the disjunctive table and redo the iterative PCA.
* Add a positive constraint to some variables while doing the PCA process

For now we have only roughly modified the code with the first proposition, which could be found in the `impute_1` function (`missMDA_function` -> `estim_ncpFAMD_3` -> `imputeFAMD` -> `imputeMFA` -> `impute_1`)

```{r pca_modification}

ncp.pca <- estim_ncpFAMD_3(X.mar1, method.cv = "Kfold", verbose = T, maxiter = 100, nbsim = 20)$ncp
````
