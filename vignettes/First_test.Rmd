---
title: "First Test"
output:
  rmarkdown::html_vignette
  html_document:
    toc: true
    toc_float: true
    df_print: paged
    number_sections: true
vignette: >
  %\VignetteEngine{knitr::rmarkdown}
---

```{r dependencies, message=FALSE, warning=FALSE}
library(MASS)
library(norm)
library(VIM)
# library(ggplot2)
# library(ggpubr)
library(naniar)
library(usethis)
# library(MissMech) # removed from the CRAN repository.
# library(BaylorEdPsych) # removed from the CRAN repository.
# library(mvnmle) # cannot find
library(rlist)
library(boot)
library(devtools)
library(Amelia)
library(abind)
library(missMethods)
library(gbutils)
library(pracma)
library(gdata)
library(caret)
library(stats)
library(missMDA)
library(uwo4419)
library(qualvar)
library(dplyr)
library(data.table)
library(mix)
library(ranger)
library(FactoMineR)
# source_url('https://raw.githubusercontent.com/R-miss-tastic/website/master/static/how-to/generate/amputation.R')
# source_url('https://raw.githubusercontent.com/njtierney/naniar/master/R/mcar-test.R')
# source_url('https://raw.githubusercontent.com/njtierney/naniar/master/R/utils.R')
# source_url('https://raw.githubusercontent.com/LqNoob/Machine-Learning-Evaluation-Metrics/master/R/Classification.R')



library(MissImp)
# source("../R/utils.R")
# source("../R/generate_missingness.R")
# source("../R/produce_NA.R")
# source("../R/dummy_test_MCAR.R")
# source("../R/MissMech_TestNormality.R")
# source("../R/miss_ranger_function.R")
# source("../R/bootstrap.R")
# source("../R/jackknife.R")
# source("../R/missMDA_function.R")
# source("../R/mcar_test_combined.R")
# source("../R/VIM_kNN.R")

# set.seed(43)
```


### Generate data
#### Complete data
We generate a complete data set (Y1, Y2, Y3, Y4, Y5, Y6, Y7, Y8) with (Y1, Y2, Y3) ~ N(u1, S1), (Y4, Y5)~N(u2,S2), Y6~P(\lambda) and Y7,Y8~Binomial(prob). 


```{r Generate_complete_dataframe}
n <- 10000
mu.X <- c(1, 2, 3)
Sigma.X <- matrix(c(
  9, 3, 2,
  3, 4, 0,
  2, 0, 1
), nrow = 3)
X.complete.cont <- MASS::mvrnorm(n, mu.X, Sigma.X) # multivariate normal distribution

mu1.X <- c(9, 8)
Sigma1.X <- matrix(c(
  16, 14,
  14, 25
), nrow = 2)

X.complete.cont1 <- MASS::mvrnorm(n, mu1.X, Sigma1.X) # multivariate normal distribution

lambda <- 4.3
X.complete.discr <- stats::rpois(n, lambda) # poisson distribution


X.complete.cat <- stats::rbinom(n, size = 5, prob = 0.4) # binomial

X.complete.cat2 <- stats::rbinom(n, size = 7, prob = 0.6) # binomial

X.complete <- data.frame(cbind(X.complete.cont, X.complete.cont1, X.complete.discr, X.complete.cat, X.complete.cat2))
X.complete[, 7] <- as.factor(X.complete[, 7])
levels(X.complete[, 7]) <- c("F", "E", "D", "C", "B", "A")
X.complete[, 8] <- as.factor(X.complete[, 8])
colnames(X.complete) <- c("Y1", "Y2", "Y3", "Y4", "Y5", "Y6", "Y7", "Y8")
head(X.complete)
```



#### Add missingness

```{r add_miss_one_mechanism}
rs = generate_miss(X.complete, 0.4, mechanism = "MAR1")
```

We generate missing values first on the continuous variables (V1,...,V5), with the result in rs.con; 
on the continous + discrete varaibles (V1,...,V6), with the result in rs.con_dis; and on continous + discrete + categorical variables, with the result in rs.mix.

```{r add_miss_all_mechanism}
rs.con <- generate_miss_ls(X.complete[, 1:5], 0.4)
rs.con_dis <- generate_miss_ls(X.complete[, 1:6], 0.4)
rs.mix <- generate_miss_ls(X.complete, 0.4)
```




### Preprocessing
```{r list_of_incomplete_dataframes}
list_df.con <- list(rs.con$mcar$X.incomp, rs.con$mar1$X.incomp, rs.con$mar2$X.incomp, rs.con$mar3$X.incomp, rs.con$mnar1$X.incomp, rs.con$mnar2$X.incomp)

list_df.con_dis <- list(rs.con_dis$mcar$X.incomp, rs.con_dis$mar1$X.incomp, rs.con_dis$mar2$X.incomp, rs.con_dis$mar3$X.incomp, rs.con_dis$mnar1$X.incomp, rs.con_dis$mnar2$X.incomp)

list_df.mix <- list(rs.mix$mcar$X.incomp, rs.mix$mar1$X.incomp, rs.mix$mar2$X.incomp, rs.mix$mar3$X.incomp, rs.mix$mnar1$X.incomp, rs.mix$mnar2$X.incomp)
```


```{r preprocessing}
# Preprocess for X.complete
idx_col_num <- c(1:6)
idx_col_cat <- c(7:8)
X.complete.ord <- ordinal_encode(X.complete, idx_col_cat)
# X.complete.norm = normalize_num(X.complete.ord, idx_col_num)

# Ordinal encoder for list_df.mix
idx_col_num <- c(1:6)
idx_col_cat <- c(7:8)
i <- 1
for (df in list_df.mix) {
  list_df.mix[[i]] <- ordinal_encode(list_df.mix[[i]], idx_col_cat)
  i <- i + 1
}
```


### Statistical test for MCAR 
```{r p_val}
p_val <- 0.05
mcar_test_combined(list_df.con_dis[[3]], col_cat = c(), p_val = p_val)$test_results
```

#### Test with dummy variables

```{r dummy_test}
# dummy_test(rs.con$X.mcar,c())
test_result_dum <- data.frame() # A dataframe that record th p-values for each test
ls_test <- list("MCAR", "MAR1", "MAR2", "MAR3", "MNAR1", "MNAR2")
i <- 1
col_cat <- c(7:8)
for (ls in list(list_df.con, list_df.con_dis, list_df.mix)) {
  j <- 1
  for (df in ls) {
    if (i == 3) {
      out <- dummy_test(df, col_cat)
    }
    else {
      out <- dummy_test(df, c())
    }
    test_result_dum[i, ls_test[[j]]] <- out$p.value
    j <- j + 1
  }
  i <- i + 1
}
row.names(test_result_dum) <- c("Continuous", "Continuous+Discret", "Continous+Discret+Categorical")
print(test_result_dum)

final_result_mcar <- data.frame(test_result_dum > p_val)
final_result_mcar
```




#### Test with Little's MCAR test

```{r little's_MCAR_test}
test_result_little <- data.frame() # A dataframe that record th p-values for each test
ls_test <- list("MCAR", "MAR1", "MAR2", "MAR3", "MNAR1", "MNAR2")
i <- 1
for (ls in list(list_df.con, list_df.con_dis, list_df.mix)) {
  j <- 1
  for (df in ls) {
    out <- mcar_test(df)
    test_result_little[i, ls_test[[j]]] <- out$p.value
    j <- j + 1
  }
  i <- i + 1
}
row.names(test_result_little) <- c("Continuous", "Continuous+Discret", "Continous+Discret+Categorical")
print(test_result_little)

final_result_mcar <- data.frame(test_result_little > p_val)
final_result_mcar
```

#### Test with Hawkin's test and nonparametric test
It is slower than mcar_test.
I find the result is less reliable than the mcar_test, and it couldn't deal with large number of data

```{r missMech_test}
test_result_hawkins <- data.frame() # A dataframe that record th p-values for each Hawkin's test
test_result_nonparam <- data.frame() # A dataframe that record th p-values for each nonparametric test
ls_test <- list("MCAR", "MAR1", "MAR2", "MAR3", "MNAR1", "MNAR2")
i <- 1
for (ls in list(list_df.con, list_df.con_dis, list_df.mix)) {
  j <- 1
  for (df in ls) {
    out_missmech <- TestMCARNormality(df)
    test_result_hawkins[i, ls_test[[j]]] <- out_missmech$pvalcomb
    test_result_nonparam[i, ls_test[[j]]] <- out_missmech$pnormality
    j <- j + 1
  }
  i <- i + 1
}

row.names(test_result_hawkins) <- c("Continuous", "Continuous+Discret", "Continous+Discret+Categorical")
row.names(test_result_nonparam) <- c("Continuous", "Continuous+Discret", "Continous+Discret+Categorical")

test_result_hawkins
test_result_nonparam

final_result_mcar <- data.frame(test_result_hawkins < p_val) * data.frame(test_result_nonparam < p_val)
final_result_mcar <- data.frame(final_result_mcar == 0)
final_result_mcar
```




### Evaluation matrix
```{r}
# dens_comp
# ls_MSE
# ls_F1
```

### Summary of imputation

```{r}
# source("../R/single_imp_combined.R")
mech <- 'MAR2'
miss_prop <- 0.4
rs <- generate_miss(X.complete[,1:6], miss_prop, mechanism = mech)
df <- rs$X.incomp
col_cat <- c()
col_dis <- c(6)
n_resample <- 4#2*round(log(nrow(df)))
maxiter_tree <- 3
maxiter_pca <- 30
ncp_pca <- ncol(df)/2
learn_ncp <- FALSE
df_complete <- X.complete[,1:6]
num_mi <- 10

imp_method <- "MI_EM"
resample_method <- "bootstrap"
cat_combine_by <- "onehot"
var_cat <- "wilcox_va"
```




```{r}
res <- single_imp(
  df = df, imp_method = imp_method, resample_method = resample_method,
  n_resample = n_resample, col_cat = col_cat, col_dis = col_dis,
  maxiter_tree = maxiter_tree, maxiter_pca = maxiter_pca, ncp_pca = ncp_pca,
  learn_ncp = learn_ncp, cat_combine_by = cat_combine_by, var_cat = var_cat,
  df_complete = df_complete, num_mi=num_mi
)
```



```{r}
head(df)
head(res$imp)
head(res$imp.disj)
head(res$uncertainty)
head(res$uncertainty.disj)
res$MSE
res$F1
```

```{r}
sum(res$uncertainty, na.rm = TRUE)/(rs$real_miss_perc*10000*8)
#0.3: 2.15438
#0.5: 1.654947
#0.7: 1.210844
```





```{r bootstrap_and_jackknife}
# Create bootstrap and jackknife datasets
# Bootstrap needs big number of samples
# Jackknife has a problem with categorical variables
df_with_mv <- list_df.mix[[2]]
df_with_mv = ordinal_encode(df_with_mv,c(7:8))
df_with_mv <- factor_encode(df_with_mv, c(7:8))
ls_boot <- bootsample(df_with_mv, 7)
ls_jack <- jacksample(df_with_mv, 7)
```



```{r dict_cat}
dict_name_cat <- dict_onehot(df_with_mv, c(7:8))
```


```{r imputation_boot_FAMD}

#Imputation (for example PCA with 3 dimension)
df_with_mv = ordinal_encode(df_with_mv,c(7:8))
df_with_mv = factor_encode(df_with_mv,c(7:8))
ls.imp.pca.onehot = list()
ls.imp.pca.fact = list()
idx_col_cat = c(7:8)
i = 1
num_col = ncol(df_with_mv)
n_opt =3
for(df in ls_boot){
  df = factor_encode(df, idx_col_cat)
  #n_opt = estim_ncpFAMD_mod(df, method.cv="Kfold", verbose=F, maxiter=100)$ncp
  #for imputeFAMD_mod, the categorical data need to be ordinal encoded then factor encoded
  pca = imputeFAMD_mod(df, ncp = n_opt, maxiter = 30)
  ls.imp.pca.onehot[[i]] = data.frame(pca$tab.disj)
  ls.imp.pca.fact[[i]] = pca$completeObs
  i = i + 1
}
```



```{r combine_boot_FAMD}
rs0 <- combine_boot(ls.imp.pca.fact, col_con = c(1:5), col_dis = c(6), col_cat = c(7:8), num_row_origin = 10000, method = "factor", dict_cat = dict_name_cat, var_cat = "wilcox_va")
rs <- combine_boot(ls.imp.pca.onehot, col_con = c(1:5), col_dis = c(6), col_cat = c(7:20), num_row_origin = 10000, method = "onehot", dict_cat = dict_name_cat, var_cat = "unalike")
```



```{r imputation_jack_FAMD}
# Imputation for ls_jack (for example PCA with 3 dimension)
ls.imp.pca.onehot <- list()
ls.imp.pca.fact <- list()
i <- 1
num_col <- ncol(df_with_mv)
for (df in ls_jack) {
  df <- factor_encode(df, c(7,8))
  # Input: an incomplete dataset
  # Outout: an imputed dataset (onehot or factor for categorical)
  pca <- imputeFAMD_mod(df, ncp = 3, maxiter = 30)
  ls.imp.pca.onehot[[i]] <- data.frame(pca$tab.disj)
  ls.imp.pca.fact[[i]] <- pca$completeObs
  i <- i + 1
}
```

```{r imputation_jack_full_dataframe_FAMD}
df_full <- df_with_mv
df_full <- factor_encode(df_with_mv, c(7,8))
pca_full <- imputeFAMD_mod(df_full, ncp = 3, maxiter = 30)
imp.pca_full.onehot <- pca_full$tab.disj
imp.pca_full.fact <- pca_full$completeObs
```




```{r combine_jack_FAMD}
rs_jack0 <- combine_jack(ls.imp.pca.onehot, data.frame(imp.pca_full.onehot), col_con = c(1:5), col_dis = c(6), col_cat = c(7:20), method = "onehot", dict_cat = dict_name_cat, var_cat = "unalike")
rs_jack1 <- combine_jack(ls.imp.pca.onehot, data.frame(imp.pca_full.onehot), col_con = c(1:5), col_dis = c(6), col_cat = c(7:20), method = "onehot", dict_cat = dict_name_cat, var_cat = "wilcox_va")
```






### Single Imputation
#### (1)EM
```{r}
df_with_mv <- list_df.mix[[2]]
df_with_mv <- ordinal_encode(df_with_mv, c(7,8))
df_with_mv <- factor_encode(df_with_mv, c(7,8))
ls_boot <- bootsample(df_with_mv, 4)
ls_jack <- jacksample(df_with_mv, 4)
dict_lev <- dict_level(df_with_mv, c(7:8))
```



```{r}
# Imputation for ls_jack (for example PCA with 3 dimension)
ls.imp.em.jack.onehot <- list()
ls.imp.em.jack.fact <- list()
i <- 1
num_col <- ncol(df_with_mv)
for (df in ls_jack) {
  #df <- factor_encode(df, idx_col_cat)
  # Input: an incomplete dataset
  # Outout: an imputed dataset (onehot or factor for categorical)
  imp.em <- em_mod(df, col_cat = col_cat)
  
  ls.imp.em.jack.onehot[[i]] <- imp.em$ximp.disj
  ls.imp.em.jack.fact[[i]] <- imp.em$ximp
  i <- i + 1
}
```
```{r}
df = ls_jack[[2]]
imp.em <- em_mod(df, col_cat = idx_col_cat)
```



```{r}
head(res$ximp)
head(res$ximp.disj)
```




#### (2)Missforest
```{r}
list_df.mix[[2]] <- factor_encode(list_df.mix[[2]], idx_col_cat)
df_with_mv <- list_df.mix[[2]]
ls_boot <- bootsample(df_with_mv, 4)
ls_jack <- jacksample(df_with_mv, 4)
```

```{r}
# Imputation
ls.imp.forest.boot.onehot <- list()
ls.imp.forest.boot.fact <- list()
idx_col_cat <- c(7:8)
i <- 1
num_col <- ncol(df_with_mv)
for (df in ls_boot) {
  df <- factor_encode(df, idx_col_cat)
  imp.forest <- missForest_mod(xmis = df, maxiter = 3, ntree = 100, col_cat = idx_col_cat)
  ls.imp.forest.boot.onehot[[i]] <- imp.forest$ximp.disj
  ls.imp.forest.boot.fact[[i]] <- imp.forest$ximp
  i <- i + 1
}
```


```{r}
dict_lev <- dict_level(df_with_mv, c(7:8))
```


```{r}
ls_MSE(X.complete, ls.imp.forest.boot.fact, mask = rs.mix$mar1$R.mask, col_num = c(1:6), resample_method = "bootstrap")
ls_F1(X.complete, ls.imp.forest.boot.fact, mask = rs.mix$mar1$R.mask, dict_lev = dict_lev, col_cat = c(7:8), resample_method = "bootstrap", combine_method = "factor")
ls_F1(X.complete, ls.imp.forest.boot.onehot, mask = rs.mix$mar1$R.mask, dict_lev = dict_lev, col_cat = c(7:20), resample_method = "bootstrap", combine_method = "onehot", dict_cat = dict_name_cat)
```




```{r}
rs0 <- combine_boot(ls.imp.forest.boot.fact, col_con = c(1:5), col_dis = c(6), col_cat = c(7:8), num_row_origin = 10000, method = "factor", dict_cat = dict_name_cat, var_cat = "wilcox_va")
rs <- combine_boot(ls.imp.forest.boot.onehot, col_con = c(1:5), col_dis = c(6), col_cat = c(7:20), num_row_origin = 10000, method = "onehot", dict_cat = dict_name_cat, var_cat = "unalike")
```

```{r}
# Imputation for ls_jack (for example PCA with 3 dimension)
ls.imp.forest.jack.onehot <- list()
ls.imp.forest.jack.fact <- list()
i <- 1
num_col <- ncol(df_with_mv)
for (df in ls_jack) {
  df <- factor_encode(df, idx_col_cat)
  # Input: an incomplete dataset
  # Outout: an imputed dataset (onehot or factor for categorical)
  imp.forest <- missForest_mod(xmis = df, maxiter = 5, ntree = 100, col_cat = idx_col_cat)
  ls.imp.forest.jack.onehot[[i]] <- imp.forest$ximp.disj
  ls.imp.forest.jack.fact[[i]] <- imp.forest$ximp
  i <- i + 1
}
```

```{r}
df_full <- df_with_mv
df_full <- factor_encode(df_with_mv, idx_col_cat)
imp.forest_full <- missForest_mod(xmis = df_full, maxiter = 5, ntree = 100, col_cat = idx_col_cat)
ls.imp.forest_full.jack.onehot <- imp.forest_full$ximp.disj
ls.imp.forest_full.jack.fact <- imp.forest_full$ximp
```


```{r}
ls_MSE(X.complete, ls.imp.forest.jack.fact, mask = rs.mix$mar1$R.mask, col_num = c(1:6), resample_method = "jackknife", df_imp_full = ls.imp.forest_full.jack.fact)
```


```{r}
rs_jack0 <- combine_jack(ls.imp.forest.jack.onehot, data.frame(ls.imp.forest_full.jack.onehot), col_con = c(1:5), col_dis = c(6), col_cat = c(7:20), method = "onehot", dict_cat = dict_name_cat, var_cat = "unalike")
rs_jack1 <- combine_jack(ls.imp.forest.jack.onehot, data.frame(ls.imp.forest_full.jack.onehot), col_con = c(1:5), col_dis = c(6), col_cat = c(7:20), method = "onehot", dict_cat = dict_name_cat, var_cat = "wilcox_va")
rs_jack0
rs_jack1
```




















```{r}

imp.forest <- missForest(xmis = list_df.mix[[2]], maxiter = 5, ntree = 100, dict_cat = dict_name_cat)
imp.forest$ximp
imp.forest$ximp.disj
```

```{r}
ls_MSE(df_comp, list(imp.forest$ximp), mask, col_num)
ls_F1(df_comp, list(imp.forest$ximp), mask, col_cat)
```


#### (3)MissRanger
```{r}
list_df.mix[[2]] <- factor_encode(list_df.mix[[2]], idx_col_cat)
df_with_mv <- list_df.mix[[2]]
```




```{r}

res <- missRanger_mod(df_with_mv, col_cat = c(7:8))
```


```{r}
# head(res$ximp,10)
# head(res$ximp.disj,10)
```





#### (4)MissMDA

```{r}
list_df.mix[[2]] <- factor_encode(list_df.mix[[2]], idx_col_cat)
ncp.pca <- estim_ncpFAMD(list_df.mix[[2]], method.cv = "Kfold", verbose = T, maxiter = 50)$ncp
pca <- imputeFAMD(list_df.mix[[2]], ncp = 5)
imp.pca <- pca$comp
```

```{r}
imp.pca <- ordinal_encode(imp.pca, idx_col_cat)
imp.pca
ls_MSE(df_comp, list(imp.pca), mask, col_num)
ls_F1(df_comp, list(imp.pca), mask, col_cat)
```





#### (5)KNN
```{r}
list_df.mix[[2]] <- factor_encode(list_df.mix[[2]], c(7:8))
df_with_mv <- list_df.mix[[2]]
```




```{r}
for (df in ls_boot) {
  res <- kNN_mod(df, col_cat = c(7:8))
}
```


```{r}
# head(res$ximp)
# head(res$ximp.disj)
# head(res$R.mask)
```





















### Multiple Imputation
#### (1)MI EM(need change)
```{r}
# df_with_mv <- list_df.mix[[2]]
df_with_mv <- rs$X.incomp
df_with_mv <- factor_ordinal_encode(df_with_mv, c(7,8))
dict_lev <- dict_level(df_with_mv, c(7:8))
```



```{r}
em_mi_mod <- function(df, col_cat){
  exist_cat <- !all(c(0, col_cat) == c(0))
  if(!exist_cat){# if there are only numerical columns
    s <- mix::prelim.mix(df, 0) # do preliminary manipulations
    thetahat <- mix::em.mix(s) # ML estimate for unrestricted model
    mix::rngseed(43) # set random number generator seed
    newtheta <- mix::da.mix(s,thetahat,steps=100)
    ximp <- mix::imp.mix(s, thetahat, df) # impute under newtheta (one draw)
    return(list(ximp=ximp, ximp.disj=ximp))
  }
  
  dict_name_cat <- dict_onehot(df, col_cat)
  df.cat <- df[,col_cat]
  #prepare for em and imputation
  # The categorical columns must be ordinal encoded and they must be the first columns of the dataframe
  df_for_em <- prepare_df_for_em(df, col_cat)
  s <- mix::prelim.mix(df_for_em, length(col_cat)) # do preliminary manipulations
  thetahat <- mix::em.mix(s) # ML estimate for unrestricted model
  mix::rngseed(43) # set random number generator seed
  newtheta <- mix::da.mix(s, thetahat, steps=100)
  ximp <- mix::imp.mix(s, thetahat, df_for_em) # impute under newtheta (one draw)
  ximp <- factor_encode(data.frame(ximp), c(1:length(col_cat)))
  #rearrange columns
  cols <- colnames(df)
  ximp <- ximp[cols]
  
  #create disjonctive table
  dims <- c()
  dimnames <- list()
  dummy <- dummyVars(" ~ .", data = ximp, sep = "_")
  ximp.disj <- data.frame(predict(dummy, newdata = ximp))
  
  #construction of tensor pi
  i <- 1
  for(name in names(dict_name_cat)){
    #ximp.disj[[name]] <- df_with_mv[[name]]
    lev <- dict_name_cat[[name]]
    dims <- c(dims,length(lev))
    dimnames[[i]] <- lev
    i <- i + 1
  }
  pi <- thetahat$pi
  tensor_pi <- array(pi, dims, dimnames)
  
  #ximp.disj onehot probability
  cat_name <- unlist(dict_name_cat)
  ximp.disj[cat_name] <- t(apply(as.matrix(df.cat),1,
                                 FUN=function(x) prob_vector_cat(x, tensor_pi,dict_name_cat)))
  return(list(ximp=data.frame(ximp), ximp.disj=data.frame(ximp.disj)))
}
```




#### (2)MI EM Amelia
```{r}
# EMB (with bootstrap option, but here we've turned it off)
# multivariate normal assumption
df_comp <- X.complete
# df_with_mv <- list_df.mix[[2]]
mask <- data.frame(is.na(df_with_mv))

res<- MI_em_amelia(df_with_mv, col_num=c(1:6), col_cat=c(7:8), num_imp=10)


# performance
# list_df.mix[[2]]
# result_imp_em_mi
# variance_imp_em_mi
# dens_comp(df_comp[, col_num], result_imp_em_mi[, col_num])
ls_MSE(df_comp, res$ls_ximp, mask, c(1:6), resample_method = "mi")
#ls_F1(df_comp, imp_amelia$imputations, mask, col_cat)
```


```{r}
head(res$ximp)
head(res$ximp.disj)


```



#### (3) MI mice
```{r}

```





#### (4) MI PCA
```{r}
df_comp <- X.complete
# df_with_mv <- list_df.mix[[2]]
df_with_mv <- generate_miss(df_comp, 0.4, mechanism = "MAR1")$X.incomp
mask <- data.frame(is.na(df_with_mv))

res<- missMDA::MIFAMD(df_with_mv, ncp=2, maxiter = 50)
```

#### (5) MI MissForest
```{r}

```



### Test with different missing proportion

```{r different_miss_prop}
mech <- 'MAR1'
# miss_prop <- 0.7
df_complete <- X.complete
# df <- generate_miss(X.complete, miss_prop, mechanism = mech)$X.incomp
col_cat <- c(7,8)
col_dis <- c(6)
n_resample <- 2*round(log(nrow(df_complete)))
maxiter_tree <- 3
maxiter_pca <- 50
ncp_pca <- round(ncol(df_complete)/2)
learn_ncp <- FALSE


imp_method <- "PCA"
resample_method <- "jackknife"
cat_combine_by <- "onehot"
var_cat <- "wilcox_va"

```


```{r different_miss_prop}
i <- 1
result <- list()
for(miss_prop in c(0.01, 0.03, 0.07, 0.1, 0.2, 0.3, 0.5, 0.7)){
  print(miss_prop)
  rs <- generate_miss(df_complete, miss_prop, mechanism = mech)
  miss_prop_real <- rs$real_miss_perc
  df_incomp <- rs$X.incomp
  result[["mechanisme"]][i] <- mech
  result[["miss_perc"]][i] <- miss_prop_real
  result[["method"]][i] <- imp_method
  result[["resample"]][i] <- resample_method
  res_imp <- single_imp(df = df_incomp, imp_method = imp_method, 
                        resample_method = resample_method, n_resample = n_resample, 
                        col_cat = col_cat, col_dis = col_dis,
                        maxiter_tree = maxiter_tree, maxiter_pca = maxiter_pca, 
                        ncp_pca = ncp_pca, learn_ncp = learn_ncp, 
                        cat_combine_by = cat_combine_by, var_cat = var_cat,
                        df_complete = df_complete, num_mi=10)
  result[["MSE"]][i] <- res_imp$MSE$Mean_MSE
  result[["Var_MSE"]][i] <- res_imp$MSE$Variance_MSE
  result[["F1"]][i] <- res_imp$F1$Mean_F1
  result[["Var_F1"]][i] <- res_imp$F1$Variance_F1
  i <- i + 1
}

data.frame(result)
```

```{r}
write.csv(result,"test_MAR1_PCA_jack_witho_i_result.csv")
read.csv("test_MAR1_PCA_jack_witho_i_result.csv")
```












